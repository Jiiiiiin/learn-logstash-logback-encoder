<?xml version="1.0" encoding="UTF-8"?>
<configuration debug="false" scan="true">
  <property resource="application.properties"/>

  <property name="log.path" value="${user.dir}/logs/${spring.application.name}"/>

  <!-- 彩色日志格式 -->
  <property name="CONSOLE_LOG_PATTERN"
    value="${CONSOLE_LOG_PATTERN:-%clr(%d{yyyy-MM-dd HH:mm:ss.SSS}){faint} %clr(${LOG_LEVEL_PATTERN:-%5p}) %clr(${PID:- }){magenta} %clr(---){faint} %clr([%15.15t]){faint} %clr(%-40.40logger{39}){cyan} %clr(:){faint} %m%n${LOG_EXCEPTION_CONVERSION_WORD:-%wEx}}"/>
  <!-- 彩色日志依赖的渲染类 -->
  <conversionRule conversionWord="clr"
    converterClass="org.springframework.boot.logging.logback.ColorConverter"/>
  <conversionRule conversionWord="wex"
    converterClass="org.springframework.boot.logging.logback.WhitespaceThrowableProxyConverter"/>
  <conversionRule conversionWord="wEx"
    converterClass="org.springframework.boot.logging.logback.ExtendedWhitespaceThrowableProxyConverter"/>
  <!-- Console log output -->
  <appender name="console" class="ch.qos.logback.core.ConsoleAppender">
    <encoder>
      <pattern>${CONSOLE_LOG_PATTERN}</pattern>
    </encoder>
  </appender>

  <appender name="jsonConsoleAppender" class="ch.qos.logback.core.ConsoleAppender">
    <encoder class="net.logstash.logback.encoder.LogstashEncoder"/>
  </appender>

  <!-- Log file debug output -->
  <appender name="debug" class="ch.qos.logback.core.rolling.RollingFileAppender">
    <!--
    https://juejin.im/post/5b51f85c5188251af91a7525#heading-24
    file 标签用于指定被写入的文件名，可以是相对目录，也可以是绝对目录，如果上级目录不存在会自动创建，没有默认值。-->
    <file>${log.path}/debug.log</file>
    <!--  这个子标签用来描述滚动策略的。这个只有appender的class是RollingFileAppender时才需要配置。这个也会涉及文件的移动和重命名（a.log->a.log.2018.07.22）。-->
    <rollingPolicy class="ch.qos.logback.core.rolling.SizeAndTimeBasedRollingPolicy">
      <!-- .%i 结合maxHistory使用 标识出现 %i，唯一需要注意的是 %i 标记，它的使用场景是这样的，如果log文件的大小达到了maxFileSize，但是时间还没有达到滚动点，那么会创建新的log文件，并用一个递增的 %i 索引，可以为同一天的日志加上不同的后缀 index-->
      <fileNamePattern>${log.path}/%d{yyyy-MM, aux}/debug.%d{yyyy-MM-dd}.%i.log.gz</fileNamePattern>
      <!--日志文件保留天数-->
      <maxHistory>30</maxHistory>
      <!-- 限定的则是单个日志文件大小 -->
      <maxFileSize>50MB</maxFileSize>
      <!-- 所有的归档日志的大小。当超过限制时，会删掉旧的归档日志。-->
      <totalSizeCap>3GB</totalSizeCap>
    </rollingPolicy>
    <encoder>
      <!-- 对记录事件进行格式化。它干了两件事：-->
      <!--  把日志信息转换成字节数组-->
      <!--   把字节数组写入到输出流-->
      <!--格式化输出：%d表示日期，%thread表示线程名，%-5level：级别从左显示5个字符宽度%msg：日志消息，%n是换行符-->
      <pattern>%date [%thread] %-5level [%logger{50}] %file:%line - %X{req_is_debug} - %msg%n
      </pattern>
    </encoder>
  </appender>

  <!--&lt;!&ndash; Log file error output &ndash;&gt;-->
  <!--<appender name="error" class="ch.qos.logback.core.rolling.RollingFileAppender">-->
  <!--<file>${log.path}/error.log</file>-->
  <!--<rollingPolicy class="ch.qos.logback.core.rolling.SizeAndTimeBasedRollingPolicy">-->
  <!--<fileNamePattern>-->
  <!--${log.path}/%d{yyyy-MM}/error.%d{yyyy-MM-dd}.%i.log.gz-->
  <!--</fileNamePattern>-->
  <!--<maxHistory>30</maxHistory>-->
  <!--<maxFileSize>50MB</maxFileSize>-->
  <!--<totalSizeCap>3GB</totalSizeCap>-->
  <!--</rollingPolicy>-->
  <!--<encoder>-->
  <!--<pattern>%date [%thread] %-5level [%logger{50}] %file:%line - %msg%n</pattern>-->
  <!--</encoder>-->
  <!--<filter class="ch.qos.logback.classic.filter.ThresholdFilter">-->
  <!--&lt;!&ndash; 过滤器，只记录 error 级别的日志 &ndash;&gt;-->
  <!--<level>ERROR</level>-->
  <!--</filter>-->
  <!--</appender>-->

  <appender name="logstash" class="ch.qos.logback.core.rolling.RollingFileAppender">
    <file>${log.path}/logstash.log</file>
    <rollingPolicy class="ch.qos.logback.core.rolling.SizeAndTimeBasedRollingPolicy">
      <fileNamePattern>
        ${log.path}/%d{yyyy-MM}/logstash.%d{yyyy-MM-dd}.%i.log.gz
      </fileNamePattern>
      <maxHistory>30</maxHistory>
      <maxFileSize>50MB</maxFileSize>
      <totalSizeCap>3GB</totalSizeCap>
    </rollingPolicy>
    <encoder class="net.logstash.logback.encoder.LogstashEncoder">
      <!--      请求者信息字段 https://www.jianshu.com/p/a26da0c55255-->
      <!--      编码器吗，布局器和追加器默认的不包含请求者信息。请求者信息是昂贵的计算，应该在繁忙的的环境中避免使用。-->
      <!--      如果要打开请求者信息功能，在配置中包含属性<includeCallerData>。-->
      <includeCallerData>true</includeCallerData>
      <includeMdcKeyName>req_is_debug</includeMdcKeyName>
      <includeMdcKeyName>req_device_id</includeMdcKeyName>
      <includeMdcKeyName>req_user_agent</includeMdcKeyName>
      <includeMdcKeyName>req_request_uri</includeMdcKeyName>
      <includeMdcKeyName>req_request_method</includeMdcKeyName>
      <includeMdcKeyName>req_content_length</includeMdcKeyName>
      <includeMdcKeyName>req_remote_addr</includeMdcKeyName>
      <includeMdcKeyName>req_remote_user</includeMdcKeyName>
      <includeMdcKeyName>req_query_string</includeMdcKeyName>
      <includeMdcKeyName>resp_status</includeMdcKeyName>

      <!--启动时候会报错因为没有该字段，如自定义的MDC-->
      <!--<excludeMdcKeyName>req_user_agent</excludeMdcKeyName>-->
      <!--自定义字段-->
      <!--http://www.lstop.pub/2017/03/14/logback发送日志到filebeat/: customFields 自定义的字段，推荐加上HOSTNAME，计算机主机名，便于在负载均衡的情况下分辨具体的服务器-->
      <!--            Note that logback versions prior to 1.1.10 included a HOSTNAME property by default in the context. As of logback 1.1.10, the HOSTNAME property is lazily calculated (see LOGBACK-1221), and will no longer be included by default.-->
      <!--但是目前测试下来 HOSTNAME是包含的-->
      <customFields>{"app_name":"${spring.application.name}", "host_name":"${HOSTNAME}"}
      </customFields>
    </encoder>
  </appender>


  <!--  https://geeksun.iteye.com/blog/2270161-->
  <!--  logback支持异步记录日志，这样可加快程序的主流程处理速度，提高接口的qps。-->
  <!--  logback异步记录日志的原理，也是使用一个缓冲队列，当缓冲数量到一定阀值时，才把日志写到文件里。-->
  <!--  异步输出，异步的log片段必须在同步段后面，否则不起作用  -->
  <appender name="async_log_logstash" class="ch.qos.logback.classic.AsyncAppender">
    <!-- 不丢失日志.默认的,如果队列的80%已满,则会丢弃TRACT、DEBUG、INFO级别的日志 -->
    <discardingThreshold>0</discardingThreshold>
    <!-- 更改默认的队列的深度,该值会影响性能.默认值为256 -->
    <queueSize>512</queueSize>
    <!-- Copy caller data to event -->
    <includeCallerData>true</includeCallerData>
    <!-- 添加附加的appender,最多只能添加一个 -->
    <appender-ref ref="logstash"/>
  </appender>


  <!--&lt;!&ndash;  为了输出访问日志事件到文件&ndash;&gt;-->
  <!--<appender name="logstash-access" class="ch.qos.logback.core.rolling.RollingFileAppender">-->
  <!--<file>${log.path}/logstash-access.log</file>-->
  <!--<rollingPolicy class="ch.qos.logback.core.rolling.SizeAndTimeBasedRollingPolicy">-->
  <!--<fileNamePattern>${log.path}/%d{yyyy-MM, aux}/logstash-access.%d{yyyy-MM-dd}.%i.log.gz</fileNamePattern>-->
  <!--<maxHistory>30</maxHistory>-->
  <!--<maxFileSize>50MB</maxFileSize>-->
  <!--<totalSizeCap>3GB</totalSizeCap>-->
  <!--</rollingPolicy>-->
  <!--<encoder class="net.logstash.logback.encoder.LogstashAccessEncoder"/>-->
  <!--</appender>-->

  <!--  直接通过tcp模式，这种方式存在一个问题就是占用服务器JVM资源的同时，还会存在日志丢失的风险 -->
  <!--  <appender name="logstash" class="net.logstash.logback.appender.LogstashTcpSocketAppender">-->
  <!--&lt;!&ndash;    https://www.jianshu.com/p/a26da0c55255 多个目标输出&ndash;&gt;-->
  <!--    &lt;!&ndash; encoder is required &ndash;&gt;-->
  <!--    <encoder charset="UTF-8" class="net.logstash.logback.encoder.LogstashEncoder"/>-->
  <!--&lt;!&ndash;    保持连接&ndash;&gt;-->
  <!--&lt;!&ndash;    如果事件频繁的输出，在服务器闲置超时的情况下，链接一般会断掉。你能通过配置来保持链接处于激活，就像这样：&ndash;&gt;-->
  <!--    <keepAliveDuration>5 minutes</keepAliveDuration>-->
  <!--&lt;!&ndash;    重连延迟&ndash;&gt;-->
  <!--&lt;!&ndash;    如果所有的配置地址都连接失败，TCP追假器会默认在试图重连前等待30秒。&ndash;&gt;-->
  <!--    <reconnectionDelay>1 second</reconnectionDelay>-->
  <!--&lt;!&ndash;    写入缓冲区的大小&ndash;&gt;-->
  <!--&lt;!&ndash;    默认的，一个8192大小大小的缓冲区被Socket用来输出到写入流中。你能通过设定writeBufferSize的值的大小来调整。writeBufferSize设定为0的情况下，缓冲失效。如果缓冲失效，写入线程会减速，但是他会在严苛的网络环境下防止丢弃日志事件。&ndash;&gt;-->
  <!--    <writeBufferSize>16384</writeBufferSize>-->
  <!--  </appender>-->

  <!-- Level: FATAL 0  ERROR 3  WARN 4  INFO 6  DEBUG 7 -->
  <root level="INFO">
    <appender-ref ref="console"/>
    <!--        <appender-ref ref="jsonConsoleAppender"/>-->
    <!--        <appender-ref ref="debug"/>-->
    <!--<appender-ref ref="error"/>-->
    <appender-ref ref="logstash"/>
    <!--        <appender-ref ref="async_log_logstash"/>-->
  </root>
</configuration>
