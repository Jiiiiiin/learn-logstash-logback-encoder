<?xml version="1.0" encoding="UTF-8"?>
<configuration debug="false" scan="false">
    <property resource="application.properties"/>

    <!--  <springProperty scope="context" name="spring.application.name" source="spring.application.name"-->
    <!--    defaultValue="user-server"/>-->
    <property name="log.path"
              value="${user.dir}/logs/${spring.application.name}"/>

    <!-- 彩色日志格式 -->
    <property name="CONSOLE_LOG_PATTERN"
              value="${CONSOLE_LOG_PATTERN:-%clr(%d{yyyy-MM-dd HH:mm:ss.SSS}){faint} %clr(${LOG_LEVEL_PATTERN:-%5p}) %clr(${PID:- }){magenta} %clr(---){faint} %clr([%15.15t]){faint} %clr(%-40.40logger{39}){cyan} %clr(:){faint} %m%n${LOG_EXCEPTION_CONVERSION_WORD:-%wEx}}"/>
    <!-- 彩色日志依赖的渲染类 -->
    <conversionRule conversionWord="clr"
                    converterClass="org.springframework.boot.logging.logback.ColorConverter"/>
    <conversionRule conversionWord="wex"
                    converterClass="org.springframework.boot.logging.logback.WhitespaceThrowableProxyConverter"/>
    <conversionRule conversionWord="wEx"
                    converterClass="org.springframework.boot.logging.logback.ExtendedWhitespaceThrowableProxyConverter"/>
    <!-- Console log output -->
    <appender name="console" class="ch.qos.logback.core.ConsoleAppender">
        <encoder>
            <pattern>${CONSOLE_LOG_PATTERN}</pattern>
        </encoder>
    </appender>

    <!-- Log file debug output -->
    <!--<appender name="debug" class="ch.qos.logback.core.rolling.RollingFileAppender">-->
        <!--&lt;!&ndash;-->
        <!--https://juejin.im/post/5b51f85c5188251af91a7525#heading-24-->
        <!--file 标签用于指定被写入的文件名，可以是相对目录，也可以是绝对目录，如果上级目录不存在会自动创建，没有默认值。&ndash;&gt;-->
        <!--<file>${log.path}/debug.log</file>-->
        <!--&lt;!&ndash;  这个子标签用来描述滚动策略的。这个只有appender的class是RollingFileAppender时才需要配置。这个也会涉及文件的移动和重命名（a.log->a.log.2018.07.22）。&ndash;&gt;-->
        <!--<rollingPolicy class="ch.qos.logback.core.rolling.SizeAndTimeBasedRollingPolicy">-->
            <!--&lt;!&ndash; .%i 结合maxHistory使用 标识出现 %i，唯一需要注意的是 %i 标记，它的使用场景是这样的，如果log文件的大小达到了maxFileSize，但是时间还没有达到滚动点，那么会创建新的log文件，并用一个递增的 %i 索引，可以为同一天的日志加上不同的后缀 index&ndash;&gt;-->
            <!--<fileNamePattern>${log.path}/%d{yyyy-MM, aux}/debug.%d{yyyy-MM-dd}.%i.log.gz</fileNamePattern>-->
            <!--&lt;!&ndash;日志文件保留天数&ndash;&gt;-->
            <!--<maxHistory>30</maxHistory>-->
            <!--&lt;!&ndash; 限定的则是单个日志文件大小 &ndash;&gt;-->
            <!--<maxFileSize>50MB</maxFileSize>-->
            <!--&lt;!&ndash; 所有的归档日志的大小。当超过限制时，会删掉旧的归档日志。&ndash;&gt;-->
            <!--<totalSizeCap>3GB</totalSizeCap>-->
        <!--</rollingPolicy>-->
        <!--<encoder>-->
            <!--&lt;!&ndash; 对记录事件进行格式化。它干了两件事：&ndash;&gt;-->
            <!--&lt;!&ndash;  把日志信息转换成字节数组&ndash;&gt;-->
            <!--&lt;!&ndash;   把字节数组写入到输出流&ndash;&gt;-->
            <!--&lt;!&ndash;格式化输出：%d表示日期，%thread表示线程名，%-5level：级别从左显示5个字符宽度%msg：日志消息，%n是换行符&ndash;&gt;-->
            <!--<pattern>%date [%thread] %-5level [%logger{50}] %file:%line - %msg%n</pattern>-->
        <!--</encoder>-->
    <!--</appender>-->

    <!--&lt;!&ndash; Log file error output &ndash;&gt;-->
    <!--<appender name="error" class="ch.qos.logback.core.rolling.RollingFileAppender">-->
        <!--<file>${log.path}/error.log</file>-->
        <!--<rollingPolicy class="ch.qos.logback.core.rolling.SizeAndTimeBasedRollingPolicy">-->
            <!--<fileNamePattern>-->
                <!--${log.path}/%d{yyyy-MM}/error.%d{yyyy-MM-dd}.%i.log.gz-->
            <!--</fileNamePattern>-->
            <!--<maxHistory>30</maxHistory>-->
            <!--<maxFileSize>50MB</maxFileSize>-->
            <!--<totalSizeCap>3GB</totalSizeCap>-->
        <!--</rollingPolicy>-->
        <!--<encoder>-->
            <!--<pattern>%date [%thread] %-5level [%logger{50}] %file:%line - %msg%n</pattern>-->
        <!--</encoder>-->
        <!--<filter class="ch.qos.logback.classic.filter.ThresholdFilter">-->
            <!--&lt;!&ndash; 过滤器，只记录 error 级别的日志 &ndash;&gt;-->
            <!--<level>ERROR</level>-->
        <!--</filter>-->
    <!--</appender>-->

    <appender name="logstash" class="ch.qos.logback.core.rolling.RollingFileAppender">
        <file>${log.path}/logstash.log</file>
        <rollingPolicy class="ch.qos.logback.core.rolling.SizeAndTimeBasedRollingPolicy">
            <fileNamePattern>
                ${log.path}/%d{yyyy-MM}/logstash.%d{yyyy-MM-dd}.%i.log.gz
            </fileNamePattern>
            <maxHistory>30</maxHistory>
            <maxFileSize>50MB</maxFileSize>
            <totalSizeCap>3GB</totalSizeCap>
        </rollingPolicy>
        <!--{"@timestamp":"2019-07-14T21:31:10.502+08:00","@version":"1","message":"call index","logger_name":"com.example.demo.DemoApplication",
        "thread_name":"http-nio-8080-exec-1","level":"INFO","level_value":20000,
            "HOSTNAME":"zhoumideMacBook-Pro.local",
            "req_device_id":"null","req_content_length":"-1","req_request_uri":"/","req_is_debug":"null","req_request_method":"GET",
            "req_query_string":"hello=world",
            "req_user_agent":"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_14_2) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/75.0.3770.100 Safari/537.36",
        "caller_class_name":"com.example.demo.DemoApplication",
        "caller_method_name":"index","caller_file_name":"DemoApplication.java","caller_line_number":29,
            "appname":"demo",
            "host":"zhoumideMacBook-Pro.local"}-->
        <encoder class="net.logstash.logback.encoder.LogstashEncoder">
            <!--      请求者信息字段 https://www.jianshu.com/p/a26da0c55255-->
            <!--      编码器吗，布局器和追加器默认的不包含请求者信息。请求者信息是昂贵的计算，应该在繁忙的的环境中避免使用。-->
            <!--      如果要打开请求者信息功能，在配置中包含属性<includeCallerData>。-->
            <includeCallerData>true</includeCallerData>
            <includeMdcKeyName>req_is_debug</includeMdcKeyName>
            <includeMdcKeyName>req_device_id</includeMdcKeyName>
            <!--<includeMdcKeyName>req_user_agent</includeMdcKeyName>-->
            <!--<includeMdcKeyName>req_request_url</includeMdcKeyName>-->
            <includeMdcKeyName>req_request_uri</includeMdcKeyName>
            <includeMdcKeyName>req_request_method</includeMdcKeyName>
            <includeMdcKeyName>req_content_length</includeMdcKeyName>
            <includeMdcKeyName>req_query_string</includeMdcKeyName>
            <includeMdcKeyName>resp_status</includeMdcKeyName>

            <!--启动时候会报错因为没有该字段，如自定义的MDC-->
            <!--<excludeMdcKeyName>req_user_agent</excludeMdcKeyName>-->
            <!--      自定义字段-->
            <!--      除了上述的字段，你能在日志事件中全域添加其他字段，或者在逐个事件基础上添加。-->
            <!--http://www.lstop.pub/2017/03/14/logback发送日志到filebeat/: customFields 自定义的字段，推荐加上HOSTNAME，便于在负载均衡的情况下分辨具体的服务器-->
            <customFields>{"app_name":"${spring.application.name}", "host_name":"${HOSTNAME}"}</customFields>
        </encoder>
    </appender>


    <!--&lt;!&ndash;  为了输出访问日志事件到文件&ndash;&gt;-->
    <!--<appender name="logstash-access" class="ch.qos.logback.core.rolling.RollingFileAppender">-->
        <!--<file>${log.path}/logstash-access.log</file>-->
        <!--<rollingPolicy class="ch.qos.logback.core.rolling.SizeAndTimeBasedRollingPolicy">-->
            <!--<fileNamePattern>${log.path}/%d{yyyy-MM, aux}/logstash-access.%d{yyyy-MM-dd}.%i.log.gz</fileNamePattern>-->
            <!--<maxHistory>30</maxHistory>-->
            <!--<maxFileSize>50MB</maxFileSize>-->
            <!--<totalSizeCap>3GB</totalSizeCap>-->
        <!--</rollingPolicy>-->
        <!--<encoder class="net.logstash.logback.encoder.LogstashAccessEncoder"/>-->
    <!--</appender>-->

    <!--  直接通过tcp模式，这种方式存在一个问题就是占用服务器JVM资源的同时，还会存在日志丢失的风险 -->
    <!--  <appender name="logstash" class="net.logstash.logback.appender.LogstashTcpSocketAppender">-->
    <!--&lt;!&ndash;    https://www.jianshu.com/p/a26da0c55255 多个目标输出&ndash;&gt;-->
    <!--    &lt;!&ndash; encoder is required &ndash;&gt;-->
    <!--    <encoder charset="UTF-8" class="net.logstash.logback.encoder.LogstashEncoder"/>-->
    <!--&lt;!&ndash;    保持连接&ndash;&gt;-->
    <!--&lt;!&ndash;    如果事件频繁的输出，在服务器闲置超时的情况下，链接一般会断掉。你能通过配置来保持链接处于激活，就像这样：&ndash;&gt;-->
    <!--    <keepAliveDuration>5 minutes</keepAliveDuration>-->
    <!--&lt;!&ndash;    重连延迟&ndash;&gt;-->
    <!--&lt;!&ndash;    如果所有的配置地址都连接失败，TCP追假器会默认在试图重连前等待30秒。&ndash;&gt;-->
    <!--    <reconnectionDelay>1 second</reconnectionDelay>-->
    <!--&lt;!&ndash;    写入缓冲区的大小&ndash;&gt;-->
    <!--&lt;!&ndash;    默认的，一个8192大小大小的缓冲区被Socket用来输出到写入流中。你能通过设定writeBufferSize的值的大小来调整。writeBufferSize设定为0的情况下，缓冲失效。如果缓冲失效，写入线程会减速，但是他会在严苛的网络环境下防止丢弃日志事件。&ndash;&gt;-->
    <!--    <writeBufferSize>16384</writeBufferSize>-->
    <!--  </appender>-->

    <!-- Level: FATAL 0  ERROR 3  WARN 4  INFO 6  DEBUG 7 -->
    <root level="INFO">
        <appender-ref ref="console"/>
        <!--<appender-ref ref="debug"/>-->
        <!--<appender-ref ref="error"/>-->
        <appender-ref ref="logstash"/>
    </root>
</configuration>
